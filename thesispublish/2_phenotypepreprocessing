#Author: Melissa Stephen

#Run from the weight processing directory

#Extract relevant columns from the DairyNZ source file (called 11StaticWeightExtract07082018.csv)   

#1: id
#2  year of birth 
#3: contemporary group (map ref and location no/yearmonthday of weight 
#4: age in months at weight day
#5: age in days at weight day
#6: weight 

awk -F"," '{print $1"-"$4"-"$5"-"$6"-"$7"-"$9"-"$10"-"$11}' 11StaticWeightExtract07082018.csv | awk -F"-" '{print $1, $2, $5""$6"/"$7$8$9, $10, $11, $12}' | sort -k1,1 > tmp_1

#Use a join to add the animal breed group and sire official code for each animal.  
#look into the PED_PROCESSING directory to pull the animal breed group and sire official code from the ped file

#1: id
#2  year of birth 
#3: contemporary group (map ref and location no/yearmonthday of weight 
#4: age in months at weight day
#5: age in days at weight day
#6: weight 
#7: SOC (7=DNA verified sire)
#8: Animal breed group (i.e. if animals is 87.5% or greater F, BG will be F 

awk '{print $1, $2, $27}' ../ped_processing/breed_ped_breed_het_bg | sort -k1,1 > ID_BG.tmp
join tmp_1 ID_BG.tmp > tmp_2

cp tmp_2 all_weights_raw

#Age in days is fitted as a fixed covariate in the model. It is fitted as a deviation from the midpoint rather then absolute age in days.  

mind1="181"  
maxd1="280"
midd1=$((mind1+((maxd1-mind1)/2)))

mind2="281"  
maxd2="380" 
midd2=$((mind2+((maxd2-mind2)/2)))

mind3="381"
maxd3="480"
midd3=$((mind3+((maxd3-mind3)/2)))

mind4="730"
maxd4="790"
midd4=$((mind4+((maxd4-mind4)/2)))

mind5="791"
maxd5="942"
midd5=$((mind5+((maxd5-mind5)/2)))

mind6="942"
maxd6="1095"
midd6=$((mind6+((maxd6-mind6)/2)))

#Create a file for each of the age groups that will be used as traits. Add a field that is the number of days in age the animal was away from the mid-point age when it was weighed. The trait definition age is the day in the middle of the max and min age. This feild will be required to regress the weight records of each animal back to a common age in days. 

#1: ID
#2  Year of birth 
#3: Contemporary group (map ref and location no/yearmonthday of weight 
#4: Weight
#5: Sire Official Code 
#6: BreedCode
#6  count of days between middate and weight date
#7  Age in days at weigh date 

awk -v mind1=$mind1 -v  maxd1=$maxd1 -v midd1=$midd1 '$5>=mind1&&$5<maxd1{print $1, $2, $3, $6, $7, $8, $5-midd1, $5}'     tmp_2 | sort -k3,3 > w1.tmp
awk -v mind2=$mind2 -v  maxd2=$maxd2 -v midd2=$midd2 '$5>=mind2&&$5<maxd2{print $1, $2, $3, $6, $7, $8, $5-midd2, $5}'     tmp_2 | sort -k3,3 > w2.tmp
awk -v mind3=$mind3 -v  maxd3=$maxd3 -v midd3=$midd3 '$5>=mind3&&$5<maxd3{print $1, $2, $3, $6, $7, $8, $5-midd3, $5}'     tmp_2 | sort -k3,3 > w3.tmp
awk -v mind4=$mind4 -v  maxd4=$maxd4 -v midd4=$midd4 '$5>=mind4&&$5<maxd4{print $1, $2, $3, $6, $7, $8, $5-midd4, $5}'     tmp_2 | sort -k3,3 > w4.tmp
awk -v mind5=$mind5 -v  maxd5=$maxd5 -v midd5=$midd5 '$5>=mind5&&$5<maxd5{print $1, $2, $3, $6, $7, $8, $5-midd5, $5}'     tmp_2 | sort -k3,3 > w5.tmp
awk -v mind6=$mind6 -v  maxd6=$maxd6 -v midd6=$midd6 '$5>=mind6&&$5<maxd6{print $1, $2, $3, $6, $7, $8, $5-midd6, $5}'     tmp_2 | sort -k3,3 > w6.tmp

#Include only friesians 

awk '$6=="F"{print $0}' w1.tmp > w1_F.tmp
awk '$6=="F"{print $0}' w2.tmp > w2_F.tmp
awk '$6=="F"{print $0}' w3.tmp > w3_F.tmp
awk '$6=="F"{print $0}' w4.tmp > w4_F.tmp
awk '$6=="F"{print $0}' w5.tmp > w5_F.tmp
awk '$6=="F"{print $0}' w6.tmp > w6_F.tmp

#Remove outlier animals. Data loaded into Julia to calculate the mean SD and the mean across cgs. 

chmod a+x+u ../* 
JWAS
cd <current>
julia
using CSV,Statistics,LinearAlgebra,DataFrames

w1 = CSV.read("w1_F.tmp",delim =" ",header=false);
w2 = CSV.read("w2_F.tmp",delim =" ",header=false);
w3 = CSV.read("w3_F.tmp",delim =" ",header=false);
w4 = CSV.read("w4_F.tmp",delim =" ",header=false);
w5 = CSV.read("w5_F.tmp",delim =" ",header=false);
w6 = CSV.read("w6_F.tmp",delim =" ",header=false);

w1_means = by(w1, :3, w1 -> mean(w1[:4]));
w2_means = by(w2, :3, w2 -> mean(w2[:4]));
w3_means = by(w3, :3, w3 -> mean(w3[:4]));
w4_means = by(w4, :3, w4 -> mean(w4[:4]));
w5_means = by(w5, :3, w5 -> mean(w5[:4]));
w6_means = by(w6, :3, w6 -> mean(w6[:4]));

w1_sds = by(w1, :3, w1 -> std(w1[:4]));
w2_sds = by(w2, :3, w2 -> std(w2[:4]));
w3_sds = by(w3, :3, w3 -> std(w3[:4]));
w4_sds = by(w4, :3, w4 -> std(w4[:4]));
w5_sds = by(w5, :3, w5 -> std(w5[:4]));
w6_sds = by(w6, :3, w6 -> std(w6[:4]));

w1_cgs = hcat(w1_means,w1_sds[:2],makeunique=true); 
w2_cgs = hcat(w2_means,w2_sds[:2],makeunique=true); 
w3_cgs = hcat(w3_means,w3_sds[:2],makeunique=true); 
w4_cgs = hcat(w4_means,w4_sds[:2],makeunique=true); 
w5_cgs = hcat(w5_means,w5_sds[:2],makeunique=true);
w6_cgs = hcat(w6_means,w6_sds[:2],makeunique=true);

CSV.write("w1_means_sds.tmp", w1_cgs, delim = " ");
CSV.write("w2_means_sds.tmp", w2_cgs, delim = " ");
CSV.write("w3_means_sds.tmp", w3_cgs, delim = " ");
CSV.write("w4_means_sds.tmp", w4_cgs, delim = " ");
CSV.write("w5_means_sds.tmp", w5_cgs, delim = " ");
CSV.write("w6_means_sds.tmp", w6_cgs, delim = " ");  

exit()
exit

# wX_means_sds_rmNA.tmp headers = cg mean_weight standard_deviation

awk '$3!="NaN"&&$3>0{print $0}' w1_means_sds.tmp > w1_means_sds_rmNA.tmp
awk '$3!="NaN"&&$3>0{print $0}' w2_means_sds.tmp > w2_means_sds_rmNA.tmp
awk '$3!="NaN"&&$3>0{print $0}' w3_means_sds.tmp > w3_means_sds_rmNA.tmp
awk '$3!="NaN"&&$3>0{print $0}' w4_means_sds.tmp > w4_means_sds_rmNA.tmp
awk '$3!="NaN"&&$3>0{print $0}' w5_means_sds.tmp > w5_means_sds_rmNA.tmp
awk '$3!="NaN"&&$3>0{print $0}' w6_means_sds.tmp > w6_means_sds_rmNA.tmp

chmod a+x+u ../* 
JWAS
cd <current>
julia
using CSV,Statistics,LinearAlgebra,DataFrames

w1 = CSV.read("w1_means_sds_rmNA.tmp",delim =" ",header=true);
w2 = CSV.read("w2_means_sds_rmNA.tmp",delim =" ",header=true);
w3 = CSV.read("w3_means_sds_rmNA.tmp",delim =" ",header=true);
w4 = CSV.read("w4_means_sds_rmNA.tmp",delim =" ",header=true);
w5 = CSV.read("w5_means_sds_rmNA.tmp",delim =" ",header=true);
w6 = CSV.read("w6_means_sds_rmNA.tmp",delim =" ",header=true);

w1_max = mean(w1[2])+(mean(w1[3])*3)
w1_min = mean(w1[2])-(mean(w1[3])*3)

w2_max = mean(w2[2])+(mean(w2[3])*3)
w2_min = mean(w2[2])-(mean(w2[3])*3)

w3_max = mean(w3[2])+(mean(w3[3])*3)
w3_min = mean(w3[2])-(mean(w3[3])*3)

w4_max = mean(w4[2])+(mean(w4[3])*3)
w4_min = mean(w4[2])-(mean(w4[3])*3)

w5_max = mean(w5[2])+(mean(w5[3])*3)
w5_min = mean(w5[2])-(mean(w5[3])*3)

w6_max = mean(w6[2])+(mean(w6[3])*3)
w6_min = mean(w6[2])-(mean(w6[3])*3)

w1_minmax =  hcat(w1_min,w1_max) 
w2_minmax =  hcat(w2_min,w2_max)
w3_minmax =  hcat(w3_min,w3_max)
w4_minmax =  hcat(w4_min,w4_max)
w5_minmax =  hcat(w5_min,w5_max)
w6_minmax =  hcat(w6_min,w6_max)
minmaxall = vcat(w1_minmax,w2_minmax,w3_minmax,w4_minmax,w5_minmax,w6_minmax)
minmax_table = convert(DataFrame, minmaxall)

CSV.write("minmax.tmp", minmax_table, delim = " ")

exit()
exit

#minmax.tmp headers = min max, there is one row for each weight_age slice

w1_min=$( awk 'NR==2{print $1;}' minmax.tmp)
w1_max=$( awk 'NR==2{print $2;}' minmax.tmp)

w2_min=$( awk 'NR==3{print $1;}' minmax.tmp)
w2_max=$( awk 'NR==3{print $2;}' minmax.tmp)

w3_min=$( awk 'NR==4{print $1;}' minmax.tmp)
w3_max=$( awk 'NR==4{print $2;}' minmax.tmp)

w4_min=$( awk 'NR==5{print $1;}' minmax.tmp)
w4_max=$( awk 'NR==5{print $2;}' minmax.tmp)

w5_min=$( awk 'NR==6{print $1;}' minmax.tmp)
w5_max=$( awk 'NR==6{print $2;}' minmax.tmp)

w6_min=$( awk 'NR==7{print $1;}' minmax.tmp)
w6_max=$( awk 'NR==7{print $2;}' minmax.tmp)

#Exclude animals based on extreme weights. weights that are outside of 3 standard deviations of the mean. mean used is the mean of cg means, sd used is mean of cg standard deviations 

awk  -v w1_min=$w1_min -v w1_max=$w1_max '$4>w1_min&&$4<w1_max{print $0}'  w1_F.tmp  > w1_outliersanimal.tmp
awk  -v w2_min=$w2_min -v w2_max=$w2_max '$4>w2_min&&$4<w2_max{print $0}'  w2_F.tmp  > w2_outliersanimal.tmp
awk  -v w3_min=$w3_min -v w3_max=$w3_max '$4>w3_min&&$4<w3_max{print $0}'  w3_F.tmp  > w3_outliersanimal.tmp
awk  -v w4_min=$w4_min -v w4_max=$w4_max '$4>w4_min&&$4<w4_max{print $0}'  w4_F.tmp  > w4_outliersanimal.tmp
awk  -v w5_min=$w5_min -v w5_max=$w5_max '$4>w5_min&&$4<w5_max{print $0}'  w5_F.tmp  > w5_outliersanimal.tmp
awk  -v w6_min=$w6_min -v w6_max=$w6_max '$4>w6_min&&$4<w6_max{print $0}'  w6_F.tmp  > w6_outliersanimal.tmp

#Exclude animals based on cg metrics. min count = 10 animals, min standard deviation = 3 

awk '{print $3}' w1_outliersanimal.tmp  | sort | uniq -c | awk '{print $2, $1}' | sort -k1,1 > w1_cgsize.tmp
awk '{print $3}' w2_outliersanimal.tmp  | sort | uniq -c | awk '{print $2, $1}' | sort -k1,1 > w2_cgsize.tmp
awk '{print $3}' w3_outliersanimal.tmp  | sort | uniq -c | awk '{print $2, $1}' | sort -k1,1 > w3_cgsize.tmp
awk '{print $3}' w4_outliersanimal.tmp  | sort | uniq -c | awk '{print $2, $1}' | sort -k1,1 > w4_cgsize.tmp
awk '{print $3}' w5_outliersanimal.tmp  | sort | uniq -c | awk '{print $2, $1}' | sort -k1,1 > w5_cgsize.tmp
awk '{print $3}' w6_outliersanimal.tmp  | sort | uniq -c | awk '{print $2, $1}' | sort -k1,1 > w6_cgsize.tmp

awk 'NR>1{print $0}' w1_means_sds.tmp | sort -k1,1 > w1_means_sds_srt.tmp
awk 'NR>1{print $0}' w2_means_sds.tmp | sort -k1,1 > w2_means_sds_srt.tmp
awk 'NR>1{print $0}' w3_means_sds.tmp | sort -k1,1 > w3_means_sds_srt.tmp
awk 'NR>1{print $0}' w4_means_sds.tmp | sort -k1,1 > w4_means_sds_srt.tmp
awk 'NR>1{print $0}' w5_means_sds.tmp | sort -k1,1 > w5_means_sds_srt.tmp
awk 'NR>1{print $0}' w6_means_sds.tmp | sort -k1,1 > w6_means_sds_srt.tmp

join w1_cgsize.tmp w1_means_sds_srt.tmp > w1_cg_metrics.tmp
join w2_cgsize.tmp w2_means_sds_srt.tmp > w2_cg_metrics.tmp
join w3_cgsize.tmp w3_means_sds_srt.tmp > w3_cg_metrics.tmp
join w4_cgsize.tmp w4_means_sds_srt.tmp > w4_cg_metrics.tmp
join w5_cgsize.tmp w5_means_sds_srt.tmp > w5_cg_metrics.tmp
join w6_cgsize.tmp w6_means_sds_srt.tmp > w6_cg_metrics.tmp

join -1 3 -2 1 w1_outliersanimal.tmp w1_cg_metrics.tmp > w1_withcgmetrics.tmp
join -1 3 -2 1 w2_outliersanimal.tmp w2_cg_metrics.tmp > w2_withcgmetrics.tmp
join -1 3 -2 1 w3_outliersanimal.tmp w3_cg_metrics.tmp > w3_withcgmetrics.tmp
join -1 3 -2 1 w4_outliersanimal.tmp w4_cg_metrics.tmp > w4_withcgmetrics.tmp
join -1 3 -2 1 w5_outliersanimal.tmp w5_cg_metrics.tmp > w5_withcgmetrics.tmp
join -1 3 -2 1 w6_outliersanimal.tmp w6_cg_metrics.tmp > w6_withcgmetrics.tmp

awk '$9>10&&$11!=NaN&&$11>3{print $0}' w1_withcgmetrics.tmp | awk '{print $2, $3, $1, $4, $5, $6, $7, $8}' > w1_outliers.tmp
awk '$9>10&&$11!=NaN&&$11>3{print $0}' w2_withcgmetrics.tmp | awk '{print $2, $3, $1, $4, $5, $6, $7, $8}' > w2_outliers.tmp
awk '$9>10&&$11!=NaN&&$11>3{print $0}' w3_withcgmetrics.tmp | awk '{print $2, $3, $1, $4, $5, $6, $7, $8}' > w3_outliers.tmp
awk '$9>10&&$11!=NaN&&$11>3{print $0}' w4_withcgmetrics.tmp | awk '{print $2, $3, $1, $4, $5, $6, $7, $8}' > w4_outliers.tmp
awk '$9>10&&$11!=NaN&&$11>3{print $0}' w5_withcgmetrics.tmp | awk '{print $2, $3, $1, $4, $5, $6, $7, $8}' > w5_outliers.tmp
awk '$9>10&&$11!=NaN&&$11>3{print $0}' w6_withcgmetrics.tmp | awk '{print $2, $3, $1, $4, $5, $6, $7, $8}' > w6_outliers.tmp

#Exclude animals based on year of birth. Include animals born after 1995

year="1995"

awk -v year=$year '$2>year&&$2{print $0}' w1_outliers.tmp | sort -k1,1 > w1_outliers_plusY.tmp
awk -v year=$year '$2>year&&$2{print $0}' w2_outliers.tmp | sort -k1,1 > w2_outliers_plusY.tmp
awk -v year=$year '$2>year&&$2{print $0}' w3_outliers.tmp | sort -k1,1 > w3_outliers_plusY.tmp
awk -v year=$year '$2>year&&$2{print $0}' w4_outliers.tmp | sort -k1,1 > w4_outliers_plusY.tmp
awk -v year=$year '$2>year&&$2{print $0}' w5_outliers.tmp | sort -k1,1 > w5_outliers_plusY.tmp
awk -v year=$year '$2>year&&$2{print $0}' w6_outliers.tmp | sort -k1,1 > w6_outliers_plusY.tmp

#Exclude duplicate measures. Each animal is only permitted to have one measure for each time slice.   
 
awk '{print $0, $1}' w1_outliers_plusY.tmp | uniq -f8 | awk '{print $1, $2, $3, $4, $5, $6, $7, $8}' | sort -k1,1  > w1_outliers_plusY_1rec.tmp
awk '{print $0, $1}' w2_outliers_plusY.tmp | uniq -f8 | awk '{print $1, $2, $3, $4, $5, $6, $7, $8}' | sort -k1,1 > w2_outliers_plusY_1rec.tmp
awk '{print $0, $1}' w3_outliers_plusY.tmp | uniq -f8 | awk '{print $1, $2, $3, $4, $5, $6, $7, $8}' | sort -k1,1 > w3_outliers_plusY_1rec.tmp
awk '{print $0, $1}' w4_outliers_plusY.tmp | uniq -f8 | awk '{print $1, $2, $3, $4, $5, $6, $7, $8}' | sort -k1,1 > w4_outliers_plusY_1rec.tmp
awk '{print $0, $1}' w5_outliers_plusY.tmp | uniq -f8 | awk '{print $1, $2, $3, $4, $5, $6, $7, $8}' | sort -k1,1 > w5_outliers_plusY_1rec.tmp
awk '{print $0, $1}' w6_outliers_plusY.tmp | uniq -f8 | awk '{print $1, $2, $3, $4, $5, $6, $7, $8}' | sort -k1,1 > w6_outliers_plusY_1rec.tmp

cp w1_outliers_plusY_1rec.tmp w1
cp w2_outliers_plusY_1rec.tmp w2
cp w3_outliers_plusY_1rec.tmp w3
cp w4_outliers_plusY_1rec.tmp w4
cp w5_outliers_plusY_1rec.tmp w5
cp w6_outliers_plusY_1rec.tmp w6 

#Add a field to the H file that is days age at parturition - this is than used to calculate days between parturition and calving). This will be an additional fixed covariate in the model. 

awk -F, '{print $1, $4}' ../4ParturitionsExtract07082018.csv | sort -u > animalPART.tmp
awk -F, '{print $1, $4}' ../11StaticWeightExtract07082018.csv | sort -u > animalDOB.tmp
join animalPART.tmp animalDOB.tmp > animalPARTDOB.tmp
awk '{print $1"-"$2"-"$3}' animalPARTDOB.tmp | awk -F"-" '{print $1, ($2-$5), (($2*365)+($3*30.42)+$4)-(($5*365)+($6*30.42)+$7)}' | awk '$2=="2"{print $1,$3}' > ageHcalving.tmp
awk '{print $1}' ageHcalving.tmp | sort | uniq -c | awk '$1==1{print $2}'| sort > nodup.tmp

join ageHcalving.tmp nodup.tmp > ageHcalving_nodup.tmp

#Headers: id,yob,cg,weight,SOC,breed,age_dev,age_on_weigh_day,days_post_calving_on_weigh_day

join w4 ageHcalving_nodup.tmp | awk '{print $1, $2, $3, $4, $5, $6, $7, $8, $8-$9}' > w4_p
join w5 ageHcalving_nodup.tmp | awk '{print $1, $2, $3, $4, $5, $6, $7, $8, $8-$9}' > w5_p
join w6 ageHcalving_nodup.tmp | awk '{print $1, $2, $3, $4, $5, $6, $7, $8, $8-$9}' > w6_p

mv w4_p w4
mv w5_p w5
mv w6_p w6

#rm *tmp*

#cp the w files to a working directory 
